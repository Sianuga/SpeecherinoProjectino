print(f"ğŸ“„ Log CSV: {log_path}")
print(f"ğŸ“ Wyniki zapisane w folderze: ./Results")
print("\nâœ… Wszystkie testy zakoÅ„czone!")

            ])
                status
                filename,
                round(rtf, 2),
                round(duration, 2),
                speed,
                text[:60] + "...",
                MODEL_NAME,
                datetime.now().isoformat(timespec="seconds"),
            writer.writerow([
            writer = csv.writer(f)
        with open(log_path, "a", newline="", encoding="utf-8") as f:
        # zapis do CSV

            status = f"ERROR: {e}"
            duration = rtf = 0
            print(f"âŒ BÅ‚Ä…d przy generowaniu: {e}")
        except Exception as e:

            status = "OK âœ…"
            print(f" > Processing time: {duration:.2f}s | Real-time factor: {rtf:.2f}")

            rtf = duration / audio_len_s
            audio_len_s = len(wav) / 22050
            # real-time factor (RTF)

            duration = time.time() - start
            sf.write(filename, wav, 22050)
            # zapis rÄ™czny

            )
                speed=speed
                language=LANG,
                speaker_wav=SPEAKER_WAV,
                text=text,
            wav = tts.tts(

            start = time.time()
        try:

        print(f"\nğŸ™ï¸  GenerujÄ™ test {idx} â€” prÄ™dkoÅ›Ä‡ {speed}...")
        filename = f"Results/test{idx}_speed{speed}_{timestamp}.wav"
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    for speed in SPEEDS:
for idx, text in enumerate(TEXTS, start=1):
# === GENEROWANIE AUDIO ===

#     print(f"âš ï¸  Torch.compile() pominiÄ™ty: {e}")
# except Exception as e:
#     print("âš™ï¸  Torch.compile() wÅ‚Ä…czony â€” model zoptymalizowany.")
#     tts.synthesizer.tts_model = torch.compile(tts.synthesizer.tts_model)
# try:

print("> Model zaÅ‚adowany âœ…")
tts = TTS(MODEL_NAME)
print(f"\n> ÅadujÄ™ model {MODEL_NAME}...")
# === ÅADOWANIE MODELU ===

    writer.writerow(["timestamp", "model", "text_snippet", "speed", "duration_s", "rtf", "output_file", "status"])
    writer = csv.writer(f)
with open(log_path, "w", newline="", encoding="utf-8") as f:
# === CSV ===

log_path = os.path.join("Results", "tts_results.csv")
os.makedirs("Results", exist_ok=True)
# === FOLDERY ===

]
    "Pierwszy pociÄ…g PKP odjeÅ¼dÅ¼a o szÃ³stej trzydzieÅ›ci rano, a drugi o siÃ³dmej piÄ™tnaÅ›cie. Na dworcu spotkaÅ‚em pracownika PKO Banku Polskiego. PowiedziaÅ‚: 'ProszÄ™ uwaÅ¼aÄ‡, dziÅ› moÅ¼e byÄ‡ opÃ³Åºnienie!'. Na szczÄ™Å›cie podrÃ³Å¼ przebiegÅ‚a bez problemÃ³w."
    "ProszÄ™ dodaÄ‡ dziesiÄ™Ä‡ mililitrÃ³w H2O i podgrzaÄ‡ roztwÃ³r do osiemdziesiÄ™ciu stopni Celsjusza. NastÄ™pnie zmieszaj skÅ‚adniki przez okoÅ‚o piÄ™Ä‡ minut. CaÅ‚y proces opisaÅ‚em w raporcie dla Sp. z o.o. BioLab. Eksperyment zakoÅ„czyÅ‚ siÄ™ peÅ‚nym sukcesem.",
    "Spotkanie odbÄ™dzie siÄ™ 12 grudnia 2025 roku o godzinie 14:45. Na sali bÄ™dzie okoÅ‚o trzystu piÄ™Ä‡dziesiÄ™ciu uczestnikÃ³w. To juÅ¼ trzecia edycja tego wydarzenia. W poprzednim roku liczba goÅ›ci przekroczyÅ‚a tysiÄ…c osÃ³b.",
    "Wczoraj byÅ‚em na konferencji AI Future Summit w Warszawie. PrezentacjÄ™ prowadziÅ‚ doktor Smith z firmy OpenAI. OpowiadaÅ‚ o nowych modelach jÄ™zykowych i ich wpÅ‚ywie na edukacjÄ™. To byÅ‚o naprawdÄ™ inspirujÄ…ce wydarzenie!",
TEXTS = [
# === TEKSTY TESTOWE ===

print(f"ğŸ§  DostÄ™pne rdzenie CPU: {os.cpu_count()}")

os.environ["PYTORCH_JIT"] = "1"
os.environ["COQUI_TTS_PROGRESS_BAR"] = "0"
os.environ["COQUI_TTS_DEBUG"] = "0"
os.environ["COQUI_TTS_LOGGER_LEVEL"] = "ERROR"
os.environ["MKL_NUM_THREADS"] = "5"
os.environ["OMP_NUM_THREADS"] = "5"
torch.set_num_threads(5)
# === OPTYMALIZACJA ÅšRODOWISKA ===

SPEEDS = [1.0]
LANG = "pl"
SPEAKER_WAV = r"C:\Users\tomas\Documents\Github\SpeecherinoProjectino\Data\Recordings\Audio_1_1.wav"
MODEL_NAME = "tts_models/multilingual/multi-dataset/xtts_v2"
# === KONFIGURACJA ===

import soundfile as sf
import torch
from TTS.api import TTS
from datetime import datetime
import time
import csv
import os
